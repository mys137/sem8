# -*- coding: utf-8 -*-
"""Asgn_2_OCR.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1QJZBIiZOi5ckgrFTjEi7uu7wJpV7WmEW
"""

import pandas as pd
import numpy as np
import tensorflow as tf
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
from keras.utils import to_categorical
from sklearn.preprocessing import StandardScaler

# Load the dataset
url = "https://archive.ics.uci.edu/ml/machine-learning-databases/letter-recognition/letter-recognition.data"
df = pd.read_csv(url, header=None)

# Split features and target
X = df.iloc[:, 1:].values.astype(float)
y = df.iloc[:, 0].values.astype(str)

# Encode the target variable
le = LabelEncoder()
y = le.fit_transform(y)

# One-hot encode the target variable
y = to_categorical(y)

df.head()

# Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Scale the features
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

model = tf.keras.models.Sequential([
    tf.keras.layers.Dense(128, activation='relu', input_shape=(X_train.shape[1],)),
    tf.keras.layers.Dense(64, activation='relu'),
    tf.keras.layers.Dense(26, activation='softmax')
])

model.summary()

model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])

history = model.fit(X_train_scaled, y_train, epochs=100, validation_split=0.2)

loss, accuracy = model.evaluate(X_test_scaled, y_test)
print('Test loss:', loss)
print('Test accuracy:', accuracy)

